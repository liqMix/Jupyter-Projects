{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS445 - HW #4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz8vbwweFapE",
        "colab_type": "text"
      },
      "source": [
        "###Spam Classifying Naive Bayes - Brady Young\n",
        "---\n",
        "\n",
        "For this project I implemented a Naive Bayes classifier that differentiates between spam e-mails and legitimate e-mails. The distribution of each feature is calculated for both the spam and non-spam classes. These distributions are used in combination with the gaussian function to calculate a given feature's \"distance\" from the class' distribution. For a given instance, these distances are totaled separately for each class and the \"closest\" class, or the one with the highest probablity is the assigned class. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "083RxK-hF31a",
        "colab_type": "text"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAvkE3zzFphP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np                #Used for array operations\n",
        "import math                       #Used for mathematical constants(e, pi) and log\n",
        "import requests                   #Used to download dataset\n",
        "import os                         #Used to manage filesystem\n",
        "import random as rand             #Used to shuffle dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxrLhFTBGxZx",
        "colab_type": "text"
      },
      "source": [
        "##Data Acquisition, Preprocessing, and Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4brx7WufRcJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creates directory for writing data files\n",
        "if(os.path.isdir('data') == False):\n",
        "  os.makedirs('data')\n",
        "  \n",
        "#Writes dataset and remote location to local files\n",
        "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
        "r = requests.get(link)\n",
        "with open('data/spambase.data', 'wb') as file:\n",
        "  file.write(r.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEU9hJ4ZfMri",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38P47I-WfMIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A wrapper to process the dataset after reading\n",
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.trainset = []\n",
        "    self.testset = []\n",
        "    self.goalset = []\n",
        "    self.testgoalset = []\n",
        "    \n",
        "    self.load()\n",
        "    self.process()\n",
        "\n",
        "  #Copies the data into memory\n",
        "  def load(self):\n",
        "    with open('data/spambase.data', mode='r') as file:\n",
        "      self.fileIn = file.read()\n",
        "    \n",
        "  def process(self):\n",
        "    featureSets = self.fileIn.split(\"\\n\")\n",
        "    rand.shuffle(featureSets)\n",
        "    \n",
        "    for i in range(int(len(featureSets)/2)):\n",
        "      self.trainset.append(featureSets[i].split(\",\"))\n",
        "      self.testset.append(featureSets[i+1].split(\",\"))\n",
        "      \n",
        "      #Grab the target from each instance\n",
        "      self.goalset.append(self.trainset[-1].pop())\n",
        "      self.testgoalset.append(self.testset[-1].pop())\n",
        "      i += 1\n",
        "      \n",
        "      #For some reason there is an occasional empty set added\n",
        "      if(self.trainset[-1] == []):\n",
        "        self.trainset.pop()\n",
        "        self.goalset.pop()\n",
        "        \n",
        "      if(self.testset[-1] == []):\n",
        "        self.testset.pop()\n",
        "        self.testgoalset.pop()\n",
        "\n",
        "    self.trainset = np.array(self.trainset, 'float64')\n",
        "    self.testset = np.array(self.testset, 'float64')\n",
        "    self.goalset = np.array(self.goalset, 'float64')\n",
        "    self.testgoalset = np.array(self.testgoalset, 'float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7N-HIe9US9q",
        "colab_type": "text"
      },
      "source": [
        "###Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgruDWbUWDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confMat(confMat):\n",
        "  print(\"\\t\\t Target\")\n",
        "  print(\"\\t\\tFalse\\tTrue\")\n",
        "  print(\"Result\\tFalse\\t\", confMat[0][0], \"\\t\", confMat[0][1])\n",
        "  print(\"\\tTrue\\t\", confMat[1][0], \"\\t\", confMat[1][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOUQgCrAnA-H",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMslfBwnAQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayes:\n",
        "  def __init__(self, dataset):\n",
        "    #Instantiate the dataset\n",
        "    self.data = dataset\n",
        "    \n",
        "    #Establish spam prior (not spam prior = 1-spam prior)\n",
        "    self.prior = np.sum(self.data.goalset) / len(self.data.goalset)\n",
        "    \n",
        "    #Small value to modify STD with\n",
        "    self.epsilon = 0.0001\n",
        "    self.confMat = np.zeros((2, 2))\n",
        "    \n",
        "    #Holds statistical data for each class\n",
        "    self.spamAvg = []\n",
        "    self.spamSTD = []\n",
        "    self.notAvg = []\n",
        "    self.notSTD = []\n",
        "\n",
        "    #Execution\n",
        "    self.computeStats()\n",
        "    self.run()\n",
        "    self.calcResults()\n",
        "    self.printResults()\n",
        "    \n",
        "  #Computes the averages and standard deviations\n",
        "  #for each feature for each class\n",
        "  def computeStats(self):\n",
        "    numberOfFeatures = len(self.data.trainset[0])\n",
        "    numberOfInstances = len(self.data.trainset)\n",
        "    spamSet = []\n",
        "    notSet = []\n",
        "    \n",
        "    for i in range(len(self.data.trainset)):\n",
        "      if(self.data.goalset[i]):\n",
        "        spamSet.append(self.data.trainset[i])\n",
        "      else:\n",
        "        notSet.append(self.data.trainset[i])\n",
        "    \n",
        "    spamSet = np.array(spamSet)\n",
        "    notSet = np.array(notSet)\n",
        "    \n",
        "    #Separates each feature into its own list\n",
        "    spamFeatureLists = np.hsplit(spamSet, numberOfFeatures)\n",
        "    notFeatureLists = np.hsplit(notSet, numberOfFeatures)\n",
        "\n",
        "    for f in spamFeatureLists:\n",
        "      self.spamAvg.append(np.sum(f) / numberOfInstances)\n",
        "      self.spamSTD.append(np.std(f) + self.epsilon)\n",
        "      \n",
        "    for f in notFeatureLists:\n",
        "      self.notAvg.append(np.sum(f) / numberOfInstances)\n",
        "      self.notSTD.append(np.std(f) + self.epsilon)\n",
        "    \n",
        "    \n",
        "  #Classifies each instance in the test set\n",
        "  def run(self):\n",
        "    for i in range(len(self.data.testset)):\n",
        "      result = self.classify(self.data.testset[i])\n",
        "      target = int(self.data.testgoalset[i])\n",
        "      \n",
        "      self.confMat[result][target] += 1\n",
        "  \n",
        "  \n",
        "  #Iterates through each feature, calculating conditional probablity given the class\n",
        "  #Returns the class with the highest probablity\n",
        "  def classify(self, features):\n",
        "    #Index 0 = not spam\n",
        "    #      1 = spam\n",
        "    prob = [math.log(1-self.prior), math.log(self.prior)]\n",
        "    for i in range(len(features)):\n",
        "      prob[0] += math.log(self.gaussian(features[i], self.notAvg[i], self.notSTD[i]))\n",
        "      prob[1] += math.log(self.gaussian(features[i], self.spamAvg[i], self.spamSTD[i]))\n",
        "    \n",
        "    return prob.index(max(prob))\n",
        "  \n",
        "  \n",
        "  #Computes the gaussian \n",
        "  def gaussian(self, feature, mean, std):\n",
        "    expNumer = (feature - mean) ** 2\n",
        "    expDenom = (std ** 2) * 2\n",
        "    exponent = -1 * (expNumer / expDenom)\n",
        "    \n",
        "    denom = math.sqrt(2 * math.pi) * std\n",
        "    numer = math.e ** exponent\n",
        "    \n",
        "    gaussian = numer/denom\n",
        "    \n",
        "    #log undefined at 0, set to small value instead\n",
        "    if(gaussian == 0):\n",
        "      return self.epsilon\n",
        "    \n",
        "    return gaussian\n",
        "  \n",
        "  \n",
        "  #Calculates the accuracy, precision, and recall of the results\n",
        "  def calcResults(self):\n",
        "    #Confusion Matrix = [result][target]\n",
        "    trueP = self.confMat[1][1]\n",
        "    trueN = self.confMat[0][0]\n",
        "    falseP = self.confMat[1][0]\n",
        "    falseN = self.confMat[0][1]\n",
        "    \n",
        "    self.accuracy = (trueP + trueN) / len(self.data.testset)\n",
        "    self.precision = trueP / (trueP + falseP)\n",
        "    self.recall = trueP / (trueP + falseN)\n",
        "    \n",
        "    \n",
        "  #Prints the results  \n",
        "  def printResults(self):\n",
        "    print(\"Accuracy: \", self.accuracy)\n",
        "    print(\"Precision: \", self.precision)\n",
        "    print(\"Recall: \", self.recall)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF6qP8BQ-9zB",
        "colab_type": "text"
      },
      "source": [
        "##Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM4ZA4lmuxyo",
        "colab_type": "code",
        "outputId": "b2197a7b-01c3-4d7c-e238-c725e2761505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset = Dataset()\n",
        "naive = NaiveBayes(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6936114732724902\n",
            "Precision:  0.5601328903654486\n",
            "Recall:  0.9514672686230248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG1SYsyd9o3E",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOgYf6z-9lZ7",
        "colab_type": "code",
        "outputId": "10d7a5bf-7cb4-4a30-d2dc-d6f80e3c84cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "confMat(naive.confMat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t Target\n",
            "\t\tFalse\tTrue\n",
            "Result\tFalse\t 753.0 \t 43.0\n",
            "\tTrue\t 662.0 \t 843.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Xs1HTSV2xx",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sREeBd5gOFG2",
        "colab_type": "text"
      },
      "source": [
        "### Usability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahze5xiIOgAv",
        "colab_type": "text"
      },
      "source": [
        "It seems that my model classifies more false-positives than false-negatives. This results in real e-mail being classified as spam at a high rate. Before using this to classify e-mail for my own inbox, I would definitely want to minimize the amount of false-positives. It would be better to occasionally see spam in my inbox than miss important e-mails due to inaccurate classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjn1Kpr_dSLG",
        "colab_type": "text"
      },
      "source": [
        "### SVM Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x2yZRMPV6Ws",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of this model tends to about 70%, with the variance due to selection of training and test sets. This falls below the general accuracy of the naive SVM classifier which incorporated the whole feature set and varied around 80% by about 10 percentage points. Notably, the precision and recall between the two systems differed as well. While the precision of the naive bayes is fairly low, around 60%, the precision of the SVM was generally around 90%. However, the recall of the naive bayes model is reliably higher, around 94%, while the SVM recall was generally quite a bit less, often under 60%. Overall though, my tuned SVM that considered only the highest weighted features had better accuracy and precision, while just a bit less recall than the Naive Bayes model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbXzFMXdVCg",
        "colab_type": "text"
      },
      "source": [
        "### Feature Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1aAE73bdgEf",
        "colab_type": "text"
      },
      "source": [
        "Reading through the names of the features as described (https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names) leads me believe that there are features in the set that are interdependent, namely the last three which describe the number of capital letters. Despite these dependencies, the model is still able to classify e-mails between spam and not spam. And it does so better than random chance on the assumption that all the features are independent from one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KSXUuLMfvrY",
        "colab_type": "text"
      },
      "source": [
        "### Performance Speculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlnqzHeeHCUa",
        "colab_type": "text"
      },
      "source": [
        "I suspect that accuracy could be increased if more features were included for instances in the dataset. If the dataset included features similar to: number of misspelled words, number of non-english words, domain of e-mail sender's e-mail address (mapped to an index). In addition, perhaps the occurence of a given word has no bearing on the class of the e-mail when considered in isolation. However, in conjunction with another word or punctuation, always exists in any given spam e-mail.\n",
        "\n",
        "It seems that features that are equally shared between classes decrease the overall accuracy of the model. The conditional probablity of a feature that is equally likely to be present in instances of both classes does not give us any information about the class the feature belongs to. I suspect some of the features from the dataset my model training were shared between classes. Specifically the features that quantified common words such as \"over\", \"our\", \"make\", \"you\". If the dataset contained only features that belonged to one class or the other, I suspect the model would be able to classify e-mails more accurately."
      ]
    }
  ]
}